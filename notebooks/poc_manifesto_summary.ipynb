{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a98f870",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation with LangChain ü¶úüîó\n",
    "# (adapted from our Challenge 'Generative AI and RAG' -> 'RAG with Langchain')\n",
    "\n",
    "In this notebook is taken from the challenge and adapted to the **political manifestos** I downloaded.\n",
    "This was just a test run: our goal of the project will be to generate summaries from the **speeches**.\n",
    "\n",
    "I created a new project environment and duplicated the requirements.txt from the challenge.\n",
    "\n",
    "https://kitt.lewagon.com/camps/2170/challenges?path=06-Deep-Learning%2F07-GenAI-and-RAG%2F03-RAG-with-LangChain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634cc8fc",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setup\n",
    "\n",
    "üëâ Run the cell below to import a couple of basic libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04eb13d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T15:46:37.525389Z",
     "iopub.status.busy": "2025-11-27T15:46:37.524862Z",
     "iopub.status.idle": "2025-11-27T15:46:47.176973Z",
     "shell.execute_reply": "2025-11-27T15:46:47.176708Z",
     "shell.execute_reply.started": "2025-11-27T15:46:37.525363Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from pprint import pprint\n",
    "from IPython.display import Markdown\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import pprint\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e75eb75c-5a66-4b3f-9c83-df3bf82cad71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T15:50:36.231979Z",
     "iopub.status.busy": "2025-11-27T15:50:36.231587Z",
     "iopub.status.idle": "2025-11-27T15:50:36.289549Z",
     "shell.execute_reply": "2025-11-27T15:50:36.289075Z",
     "shell.execute_reply.started": "2025-11-27T15:50:36.231956Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_classic import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9238f09-33bd-4e13-9688-4cfa9f5e4b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfaf3cc",
   "metadata": {},
   "source": [
    "üëâ Run the cell below to load our API key again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fc3c400",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T15:46:52.474911Z",
     "iopub.status.busy": "2025-11-27T15:46:52.473831Z",
     "iopub.status.idle": "2025-11-27T15:46:52.539366Z",
     "shell.execute_reply": "2025-11-27T15:46:52.538861Z",
     "shell.execute_reply.started": "2025-11-27T15:46:52.474885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed3c69",
   "metadata": {},
   "source": [
    "## üìö Why RAG?\n",
    "\n",
    "An LLM on its own can respond questions about everything it has learned.\n",
    "\n",
    "That has a couple of drawbacks:\n",
    "- The training data comes from the past and is not updated with the most recent data.\n",
    "- It only knows the data it was trained on.\n",
    "\n",
    "We want to use an LLM to work with our own data. That is where RAG, or Retrieval-Augmented Generation steps in.\n",
    "\n",
    "1. **Retrieval-Augmented Generation (RAG)** combines a language model with a document retriever to enhance factual accuracy.\n",
    "2. **It retrieves relevant external documents** (e.g., from a knowledge base) before generating responses.\n",
    "3. **The language model uses both the prompt and retrieved context** to produce more informed and grounded outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33584447",
   "metadata": {},
   "source": [
    "## üî¢ Embedding documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5e8dd3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T15:47:26.500544Z",
     "iopub.status.busy": "2025-11-27T15:47:26.500136Z",
     "iopub.status.idle": "2025-11-27T15:47:26.583645Z",
     "shell.execute_reply": "2025-11-27T15:47:26.583314Z",
     "shell.execute_reply.started": "2025-11-27T15:47:26.500517Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f97d04",
   "metadata": {},
   "source": [
    "Now we know what an embedding looks like, it's time to get working with our real data.\n",
    "\n",
    "üëâ Head to the [LangChain documentation](https://docs.langchain.com/oss/python/integrations/document_loaders/index#pdfs), and find out how you can load a PDF using PyPDF.\n",
    "\n",
    "üëâ Then go ahead and load one of the PDFs you downloaded before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fd062a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T15:52:03.999736Z",
     "iopub.status.busy": "2025-11-27T15:52:03.999345Z",
     "iopub.status.idle": "2025-11-27T15:52:04.060587Z",
     "shell.execute_reply": "2025-11-27T15:52:04.060189Z",
     "shell.execute_reply.started": "2025-11-27T15:52:03.999712Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "model = init_chat_model(\"google_genai:gemini-2.5-flash-lite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "768ef209-bc1c-451b-b9f9-342bb351b453",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-27T16:10:13.525084Z",
     "iopub.status.busy": "2025-11-27T16:10:13.524688Z",
     "iopub.status.idle": "2025-11-27T16:10:13.583052Z",
     "shell.execute_reply": "2025-11-27T16:10:13.582667Z",
     "shell.execute_reply.started": "2025-11-27T16:10:13.525057Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Use the following context to answer the question. Use maximum 7 sentences. Use specific terms. Highlight important ones.\"),\n",
    "    (\"human\", \"\"\"Context: {context}  Question: {question}\"\"\")\n",
    "    ])\n",
    "\n",
    "example_messages = prompt_template.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41977a17-d1ce-4d5a-b78c-6a7aabcbe5e1",
   "metadata": {},
   "source": [
    "Instantiate Vector Store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c3675f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T15:16:42.729847Z",
     "iopub.status.busy": "2025-11-29T15:16:42.729459Z",
     "iopub.status.idle": "2025-11-29T15:16:42.790983Z",
     "shell.execute_reply": "2025-11-29T15:16:42.790576Z",
     "shell.execute_reply.started": "2025-11-29T15:16:42.729823Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc8e9ca-4952-4dae-a51d-5a268281acd0",
   "metadata": {},
   "source": [
    "Write a function to populate the Vectore Store with own documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6d70dd1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T15:24:04.103429Z",
     "iopub.status.busy": "2025-11-29T15:24:04.102771Z",
     "iopub.status.idle": "2025-11-29T15:24:04.163754Z",
     "shell.execute_reply": "2025-11-29T15:24:04.163270Z",
     "shell.execute_reply.started": "2025-11-29T15:24:04.103383Z"
    }
   },
   "outputs": [],
   "source": [
    "def embed_and_store(file_path, vector_store):\n",
    "    \"\"\"Load a PDF file, split it into chunks, and store the chunks in a vector store.\"\"\"\n",
    "    # Load the PDF file\n",
    "\n",
    "\n",
    "    loader = PyPDFLoader(file_path, mode='single')\n",
    "    pdf = loader.load()\n",
    "\n",
    "    # Split the pages into chunks\n",
    "    splits = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 200)\n",
    "\n",
    "    all_splits = splits.split_documents(pdf)\n",
    "\n",
    "    # Add the party name to the metadata\n",
    "    pattern = r\"(?<=data/)[^_]+(?=_)\"\n",
    "    \n",
    "    party_name = re.search(pattern, file_path)\n",
    "\n",
    "    for split in all_splits:\n",
    "        split.metadata['party_name'] = party_name.group()\n",
    "        \n",
    "\n",
    "    # Add the chunks to the vector store\n",
    "    document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "    return f'{file_path} embedded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c0e977b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T15:24:06.416869Z",
     "iopub.status.busy": "2025-11-29T15:24:06.416031Z",
     "iopub.status.idle": "2025-11-29T15:24:24.009337Z",
     "shell.execute_reply": "2025-11-29T15:24:24.008841Z",
     "shell.execute_reply.started": "2025-11-29T15:24:06.416817Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/B90G_25Wahlprogramm.pdf embedded'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_and_store('data/B90G_25Wahlprogramm.pdf', vector_store)\n",
    "# embed_and_store('data/AfD_25Wahlprogramm.pdf', vector_store)\n",
    "# embed_and_store('data/BSW_25Wahlprogramm.pdf', vector_store)\n",
    "# embed_and_store('data/FDP_25Wahlprogramm.pdf', vector_store)\n",
    "# embed_and_store('data/SPD_25Wahlprogramm.pdf', vector_store)\n",
    "# embed_and_store('data/DieLinke_25Wahlprogramm.pdf', vector_store)\n",
    "# embed_and_store('data/CDU_25Wahlprogramm.pdf', vector_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2f788d76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T15:53:45.623122Z",
     "iopub.status.busy": "2025-11-28T15:53:45.622762Z",
     "iopub.status.idle": "2025-11-28T15:53:45.682473Z",
     "shell.execute_reply": "2025-11-28T15:53:45.682020Z",
     "shell.execute_reply.started": "2025-11-28T15:53:45.623099Z"
    }
   },
   "outputs": [],
   "source": [
    "def answer(query, vector_store, llm, party, prompt_template=None):\n",
    "    \"\"\"Answer a query using the vector store and the language model.\"\"\"\n",
    "    # Retrieve similar documents from the vector store\n",
    "    retrieved_docs = vector_store.similarity_search(query,k=6),filter={\"party_name\":party})\n",
    "\n",
    "    # Create the prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    # If no prompt template is provided, use the default one\n",
    "    if not prompt_template:\n",
    "        prompt_template = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    prompt = prompt_template.invoke(\n",
    "        {\"context\": docs_content, \"question\": query}\n",
    "    )\n",
    "\n",
    "    # Get the answer from the language model\n",
    "    answer = llm.invoke(prompt)\n",
    "    return answer.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39203f33",
   "metadata": {},
   "source": [
    "üëâ Try out your function with a query of your liking:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd178dde-825d-4c4b-841a-c1e1cd2f2abb",
   "metadata": {},
   "source": [
    "# Scenarion 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bf8085-8371-45d6-8565-57bfcef05a2d",
   "metadata": {},
   "source": [
    "Feed entire text without meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "76858e2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T15:53:46.427089Z",
     "iopub.status.busy": "2025-11-28T15:53:46.426711Z",
     "iopub.status.idle": "2025-11-28T15:53:46.484812Z",
     "shell.execute_reply": "2025-11-28T15:53:46.484327Z",
     "shell.execute_reply.started": "2025-11-28T15:53:46.427065Z"
    }
   },
   "outputs": [],
   "source": [
    "query = 'What does AfD say about migration?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9749a0b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T15:24:25.892611Z",
     "iopub.status.busy": "2025-11-29T15:24:25.892224Z",
     "iopub.status.idle": "2025-11-29T15:24:27.595232Z",
     "shell.execute_reply": "2025-11-29T15:24:27.594048Z",
     "shell.execute_reply.started": "2025-11-29T15:24:25.892587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The party advocates for **regulated migration pathways** through visa agreements and training partnerships for students, trainees, and skilled workers. They believe in **human rights-based cooperation** with third and transit countries, emphasizing that more regulated migration leads to less irregular migration. The goal is to **effectively and long-term reduce irregular and dangerous migration** to Europe by creating better local living conditions and implementing comprehensive migration agreements. They explicitly oppose outsourcing asylum procedures to third countries, citing cost and legal failures. The party also stresses the importance of distinguishing between flight and labor migration."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(answer(query, vector_store, model,None, prompt_template=prompt_template))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78523329-a1e6-4d12-80ba-520038d33921",
   "metadata": {},
   "source": [
    "# preferred: Scenario 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ad411-d458-4c39-a863-a87c84307766",
   "metadata": {},
   "source": [
    "Feed entire text with meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8cd6e4-0890-4120-88fb-d636b65296f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What does the party say about migration?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8aa003-c6b4-47f8-97a2-fece158903e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Afd#_speeches = ['ID214376','ID1694723', 'ID326294']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ada4459-6119-4b20-b1e4-20e032dff46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Markdown(answer(query, vector_store, model,['AfD','mindate','maxdat'], prompt_template=prompt_template))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
